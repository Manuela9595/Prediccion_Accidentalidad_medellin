---
title: "**Evaluación de modelos para la predicción semanal de accidentes viales con Gravedad: Muertos**<br>"

author: "*Alexis A. Arenas Bustamante, Juan E. Arroyave Duque, William A. Jovel Tamayo, Manuela Londoño Ocampo.* <br> Curso de Analítica Predictiva <br> Universidad Nacional de Colombia <br> Facultad de Minas <br> Medellín"
date: "Septiembre de 2019"

output:
  html_document:
    theme: cosmo
    highlight: haddock
    number_sections: true
    df_print: paged
    toc: true
    toc_float:
      collapsed: True
---

<style>
body {
text-align: justify}
</style>

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r setup, warning=FALSE, message=FALSE}
library(dplyr) # data wrangling
library(ranger)
library(caret)
library(corrplot)
library(rsample)     # data splitting 
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
require(MASS)
library(randomForest)
library(tidyverse)
library(ggpubr)
```

Se consideran tres modelos para la predicción semanal de los accidentes viales con muertes: Regresión lineal, Árbol de regresión y Random Forest. A continuación se presenta la evaluación de cada uno:

# **Dataset propuesto para el modelo semanal de accidentalidad vial : Muertos**

```{r, echo = FALSE}
semanal_1 <- read.csv("~/Docs/MAESTRIA/ANALITICA PREDICTIVA/Trabajo Final/Datasets/RAPIDM/SEGUNDA_CORRIDA/muertes_semanal_1.csv", sep=";")
 head(semanal_1)
```

# **Estadísticas Descriptivas**  {.tabset .tabset-fade .tabset-pills}

## **Summary del conjunto de datos**

```{r, echo=FALSE}
summary(semanal_1)
```

## **Histograma de la variable dependiente**

```{r, echo= FALSE}
library(ggplot2)

ggplot(semanal_1, aes(MUERTES)) + 
  geom_histogram(bins=9, fill = "#9999CC", position = 'identity') + 
  xlab("Accidentes con Muertos") + ylab("Frecuencia") +
  theme_classic2()

```

## **Boxplots por Periodo**

```{r hitogramas, echo=FALSE}
datosM<- semanal_1
datosM$ANYO <- as.factor(datosM$ANYO)

ggplot(datosM, aes(x=ANYO, y=MUERTES, fill=ANYO)) + 
  geom_boxplot(alpha=0.3) +
  xlab("AÑO") + ylab("Accidentes con Muertos") +
  theme(legend.position="none") + theme_classic()
```


## **Correlación entre variables consideradas**

```{r correlacion, echo=FALSE}
library(corrplot)
datosM$ANYO <- as.integer(datosM$ANYO)
M <- cor(datosM)
corrplot(M, method = "color")
```

Se puede observar que la variable mas correlacionada con la cantidad de accidentes semanales con muertes es FESTIVOS. En cada uno de los modelos se identificará la importancia de las variables, de modo que solo se incluyan aquellas que tengan una influencia significativa sobre la variables dependiente. El periodo no hará parte de ningún modelo puesto que solo se usa para la partición de los datos en conjuntos de entrenamiento y validación.

# **Partición de los datos conjuntos de train y test**

Para la validación se usaran los datos de accidentes viales ocurridos en el año 2018.

Datos de Train: Se cuenta 303 observaciones para el entrenamiento de los modelos

```{r, echo = FALSE}
muertes_train <- datosM[datosM$ANYO < 5, ]
muertes_test <- datosM[datosM$ANYO >= 5, ]

dim(muertes_train)
```

Datos de Test: Se cuenta con 74 observaciones para la validación de los modelos

```{r, echo= FALSE}
dim(muertes_test)
```

Una vez realizada la partición de los datos, se procede con la eliminación de la variable ANYO en ambos datasets.

```{r}
muertes_train <- dplyr :: select(muertes_train, -ANYO)
muertes_test <- dplyr :: select(muertes_test, -ANYO)
```

# **Modelo de predicción considerados** {.tabset .tabset-fade .tabset-pills}

## **Regresión Lineal**

**Entrenamiento del modelo**

```{r}
regresion_1 <- lm(MUERTES ~., data= muertes_train)
summary(regresion_1)
```

Se puede observar que la mayoría de variables son significativas para el modelo, a pesar de esto las métricas de ajuste no son muy buenas, por su parte el R-squared indica que el modelo logra explica solo el 39.13 % de la accidentalidad semanal con gravedad de muertes. El valor P del estadístico F en este caso es significativo.

**Métricas de Bondad para regresión lineal**

```{r, echo = FALSE}
# Compute R^2 from true and predicted values

y_pred_train_sd <- predict(regresion_1, muertes_train)
y_pred_test_sd <- predict(regresion_1, muertes_test)


reg_1 <- data.frame(RMSE_Train = RMSE(y_pred_train_sd, muertes_train$MUERTES),
                    Rsquared_Train = R2(y_pred_train_sd, muertes_train$MUERTES),
                    RMSE_Test = RMSE(y_pred_test_sd, muertes_test$MUERTES),
                    Rsquared_Test = R2(y_pred_test_sd, muertes_test$MUERTES))
reg_1
```

Comparando las métricas consideradas tanto para el entrenamiento como para la validación del modelo, se puede afirmar que para el conjunto de test el R-squared disminuyo considerablemente y en cuanto al RMSE, es posible identificar que la diferencia entre los conjuntos de entrenamiento y test es del 35 %, esto indica que el modelo presenta problemas de sobre ajuste y no es bueno para el problema de predicción propuesto.

**Ajuste de las predicciones vs valores reales**
```{r}
plot(y_pred_test_sd, muertes_test$MUERTES,las=1, xlab="Predicciones", ylab = "Accidentes con Muertos")
abline(a=1,b=1,lwd=2,col="red")
```

En el gráfico de dispersión se puede observar de mejor manera la pobre capacidad de predicción que obtuvo el modelo para la accidentalidad vial semanal con gravedad de muertos.

## **Árbol Regresor**

**Entrenamiento del modelo**

Se toma el modelo mas simple para el árbol regresor, a partir de este se realizara una búsqueda tipo grid search, de parámetros de restricción óptimos. Se definen ademas funciones para extraer el mínimo error asociado con el valor óptimo de costo de complejidad (CP) de cada modelo y el valor óptimo CP.

```{r}
set.seed(123)

dt_m <- rpart(
  formula = MUERTES ~ .,
  data    = muertes_train,
  method  = "anova"
  )
```

**Representación gráfica del árbol regresor sin tuning**

```{r, echo= FALSE}
rpart.plot(dt_m)
```

**Ajuste de parámetro de restricción para el árbol regresor**

Se realiza una búsqueda de los parámetros óptimos de minsplit y maxdepth para el árbol regresor: 

En la siguiente gráfica se puede observar el numero optimo de nodos identificado por el modelo que reduce el error asociado. Este sera el punto de partida para definir entre que valores puede variar el parámetro de profundidad del árbol. Vemos que este valor es de 8 divisiones y 9 nodos finales.

```{r}
plotcp(dt_m)

dt_sd2 <- rpart(
    formula = MUERTES ~ .,
    data    = muertes_train,
    method  = "anova", 
    control = list(cp = 0, xval = 10)
)
```

El error de validación cruzada asociado es de 0.768, este valor se puede mejorar en el proceso de tuning

```{r}
dt_m$cptable
```

El siguiente código define una función grid para la búsqueda de diferentes combinaciones de minsplit y maxdepth. También las funciones que extraen el optimo cp y el mínimo error asociado.

```{r}

hyper_grid_m <- expand.grid(
  minsplit = seq(2, 20, 1),
  maxdepth = seq(2, 30, 1)
)

models_m <- list()

for (i in 1:nrow(hyper_grid_m)) {
  
  # get minsplit, maxdepth values at row i
  minsplit <- hyper_grid_m$minsplit[i]
  maxdepth <- hyper_grid_m$maxdepth[i]

  # train a model and store in the list
  models_m[[i]] <- rpart(
    formula = MUERTES ~ .,
    data    = muertes_train,
    method  = "anova",
    control = list(minsplit = minsplit, maxdepth = maxdepth)
    )
}

# function to get optimal cp
get_cp <- function(x) {
  min    <- which.min(x$cptable[, "xerror"])
  cp <- x$cptable[min, "CP"] 
}

# function to get minimum error
get_min_error <- function(x) {
  min    <- which.min(x$cptable[, "xerror"])
  xerror <- x$cptable[min, "xerror"] 
}
```

Agregaremos los resultados de la búsqueda a la grilla de hyper-parámetros y filtraremos los 5 valores con error mínimo.

```{r}
hyper_grid_m %>%
  mutate(
    cp    = purrr::map_dbl(models_m, get_cp),
    error = purrr::map_dbl(models_m, get_min_error)
    ) %>%
  arrange(error) %>%
  top_n(-5, wt = error)
```

Vemos que el error se redujo a 0.658, lo cual indica mejores modelos en comparación con el modelo inicial. Se entrena el árbol regresor con las combinaciones que encabezan los resultados anteriores:

```{r}
optimal_tree_m <- rpart(
    formula = MUERTES ~ .,
    data    = muertes_train,
    method  = "anova",
    control = list(minsplit = 5, maxdepth = 12, cp = 0.01)
    )
```

**Métricas de Bondad para el mejor árbol regresor**

```{r}
pred_dt1_train = predict(optimal_tree_m, newdata=muertes_train)
pred_dt1_test = predict(optimal_tree_m, newdata=muertes_test)

dt_sd_op1 <- data.frame(RMSE_Train = RMSE(pred_dt1_train, muertes_train$MUERTES),
                    Rsquared_Train = R2(pred_dt1_train, muertes_train$MUERTES),
                    RMSE_Test = RMSE(pred_dt1_test, muertes_test$MUERTES),
                    Rsquared_Test = R2(pred_dt1_test, muertes_test$MUERTES))
dt_sd_op1
```

Comparando las métricas consideradas tanto para el entrenamiento como para la validación del árbol óptimo, observamos que en ambas se obtuvo un mejor R-squared en comparación con el modelo de regresión lineal y su variación es menor. La diferencia entre los RMSE es del 57%, siendo mayor que el modelo de regresión lineal expuesto anteriormente.

**Mejor árbol regresor obtenido**

```{r, echo= FALSE}
library(rpart.plot)
prp(optimal_tree_m)
```

## **Random Forest**

**Entrenamiento del modelo**

Se toma el modelo mas simple, a partir de este se realizará una búsqueda tipo grid search de los hiper parámetros óptimos, mediante el uso de la librería Range. Se analizaron en total 432 modelos diferentes con variaciones en mtry, mínimo tamaño de muestras en el nodo, y tamaño de la muestra.

```{r}
set.seed(101)
rf_sd = randomForest(MUERTES ~ ., data = muertes_train)
rf_sd
```

Inicialmente, observamos que la varianza explicada por el modelo es del 37,85 %.

**Este gráfico muestra el error vs. el número de árboles**

```{r}
plot(rf_sd)
```

 **Afinamiento del modelo Random Forest**

Se define la siguiente grilla de búsqueda:

```{r}
set.seed(101)
# hyperparameter grid search
hyper_grid_rf <- expand.grid(
  mtry       = seq(1, 9, by = 1),
  node_size  = seq(7, 30, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

# total number of combinations
#nrow(hyper_grid_rf)
```

Se utiliza la librería Ranger para la búsqueda de los mejores hyper parámetros:

```{r}
for(i in 1:nrow(hyper_grid_rf)) {
  
  # train model
  model <- ranger(
    formula         = MUERTES ~ ., 
    data            = muertes_train, 
    num.trees       = 500,
    mtry            = hyper_grid_rf$mtry[i],
    min.node.size   = hyper_grid_rf$node_size[i],
    sample.fraction = hyper_grid_rf$sampe_size[i],
    seed            = 101
  )
  
  # add OOB error to grid
  hyper_grid_rf$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

hyper_grid_rf %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)
```

Se ajusta el modelo con los mejores hyper parámetros obtenidos:

```{r}
set.seed(101)
mejorRandomforest <- randomForest(MUERTES ~., data = muertes_train, mtry = 6, 
                                  nodesize = 7, sampe_size = 0.8,
                                  ntree = 500, importance = TRUE)
mejorRandomforest

```

Con la función importance() se extrae la importancia de las variables.

```{r}
library(tidyverse)
library(ggpubr)
importancia_pred <- as.data.frame(importance(mejorRandomforest, scale = TRUE))
importancia_pred <- rownames_to_column(importancia_pred, var = "variable")
p1 <- ggplot(data = importancia_pred, aes(x = reorder(variable, `%IncMSE`),
                                          y = `%IncMSE`,
                                          fill = `%IncMSE`)) +
    labs(x = "variable", title = "Reducción de MSE") +
    geom_col() +
    coord_flip() +
    theme_bw() +
    theme(legend.position = "bottom")

p2 <- ggplot(data = importancia_pred, aes(x = reorder(variable, IncNodePurity),
                                          y = IncNodePurity,
                                          fill = IncNodePurity)) +
    labs(x = "variable", title = "Reducción de pureza") +
    geom_col() +
    coord_flip() +
    theme_bw() +
    theme(legend.position = "bottom")
ggarrange(p1, p2)
```

**Métricas de bondad para modelo de Random Forest**

```{r}
pred_randomForest_t <- predict(mejorRandomforest, muertes_train)
pred_randomForest <- predict(mejorRandomforest, muertes_test)

dt_rf_1 <- data.frame(RMSE_Train = RMSE(pred_randomForest_t, muertes_train$MUERTES),
                    Rsquared_Train = R2(pred_randomForest_t, muertes_train$MUERTES),
                    RMSE_Test = RMSE(pred_randomForest, muertes_test$MUERTES),
                    Rsquared_Test = R2(pred_randomForest, muertes_test$MUERTES))

dt_rf_1

```

Observamos que los R-squared para entrenamiento y validación son mas altos en comparación con los obtenido en los modelos de regresión lineal y Árbol regresor. El RMSE presenta una variación aproximada de 70%, a pesar de que no es la menor variación entre los modelos expuestos, la diferencia con respecto al R-squared es mas baja y basados en esta métrica se elige al RandomForest como mejor modelo.




