---
title: "**Evaluación de modelos para la predicción mensual de accidentes viales con Gravedad: Heridos**<br>"

author: "*Alexis A. Arenas Bustamante, Juan E. Arroyave Duque, William A. Jovel Tamayo, Manuela Londoño Ocampo.* <br> Curso de Analítica Predictiva <br> Universidad Nacional de Colombia <br> Facultad de Minas <br> Medellín"
date: "Septiembre de 2019"

output:
  html_document:
    theme: cosmo
    highlight: haddock
    number_sections: true
    df_print: paged
    toc: true
    toc_float:
      collapsed: True
---

<style>
body {
text-align: justify}
</style>

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Librerías Necesarias**

```{r setup, warning=FALSE, message=FALSE}
library(dplyr) # data wrangling
library(ranger)
library(caret)
library(corrplot)
library(rsample)     # data splitting 
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
require(MASS)
library(randomForest)
library(tidyverse)
library(ggpubr)
```

Se consideran tres modelos para la predicción mensual de los accidentes viales con heridos: Regresión lineal, Árbol de regresión y Random Forest. A continuación se presenta la evaluación de cada uno:


# **Dataset propuesto para el modelo mensual de accidentalidad vial : Heridos**

```{r datos_mensuales}
datos_mensualesH <- read.csv("~/Docs/MAESTRIA/ANALITICA PREDICTIVA/Trabajo Final/Datasets/RAPIDM/mensual_h_2.csv", sep=",")

head(datos_mensualesH)
```

# **Estadísticas Descriptivas**  {.tabset .tabset-fade .tabset-pills}

## **Summary del conjunto de datos**

```{r echo = FALSE}
summary(datos_mensualesH)
```

## **Histograma de la variable dependiente**

```{r hitogramas, echo=FALSE}

ggplot(datos_mensualesH, aes(HERIDOS)) + 
  geom_histogram(bins=15, fill = "#9999CC", position = 'identity') + 
  xlab("Accidentes con Heridos") + ylab("Frecuencia") +
  theme_classic2()

```

## **Boxplots por mes**

```{r, echo=FALSE}
datosH <- datos_mensualesH 
datosH$MES <- as.factor(datosH$MES)

ggplot(datosH, aes(x=MES, y=HERIDOS, fill=MES)) + 
  geom_boxplot(alpha=0.3) +
  xlab("Mes") + ylab("Accidentes Heridos") +
  theme(legend.position="none") + theme_classic()
```

Se puede observar la presencia de ciertos valores atípicos por mes. Estos se trataran por medio de la imputación con mediana.

## **Correlación entre variables consideradas**

```{r correlacion, echo=FALSE}
library(corrplot)
datosH$MES <- as.integer(datosH$MES)
M <- cor(datosH)
corrplot(M, method = "color")
```

Se puede observar que la variable mas correlacionada con la cantidad de accidentes mensuales con heridos es FESTIVOS. En cada uno de los modelos propuestos se identificará la importancia de las variables, de modo que solo se incluyan aquellas que tengan una influencia significativa sobre la variables dependiente. El periodo no hará parte de ningún modelo puesto que solo se usa para la partición de los datos en conjuntos de entrenamiento y validación.


```{r imputacion, include=FALSE}
# df es el dataFrame que recibimos (ej. activity)
# colNameData es la columna de los datos (ej. "steps")
# colNameBy es la columna por la que trocearemos (ej. "userId")

outliersReplace <- function(df, colNameData, colNameBy){
  # creamos una nueva columna llamada igual que colNameData pero con .R
  colNameData.R <- paste(colNameData, "R", sep=".")
  df[colNameData.R] <- df[colNameData]
  
  # obtenemos los IDs por los que partir el dataframe
  IDs <- unique(df[,c(colNameBy)])
  for (id in IDs){
    data <- df[df[colNameBy] == id, c(colNameData) ]
    
    Q  <- quantile(data)
    minimo <- Q[1]    # valor minimo
    Q1     <- Q[2]    # primer cuartil
    Me     <- Q[3]    # mediana
    Q3     <- Q[4]    # tercer cuartil
    maximo <- Q[5]    # valor maximo
    IQR    <- Q3 - Q1
    
    lowLimit  <- max(minimo, Q1 - 1.5*IQR)
    highLimit <- min(maximo, Q3 + 1.5*IQR)
    
    # todos los valores donde colNameBy es igual a id
    # y el valor de colNameData es > Q3 + 1.5 * IQR
    # lo reemplazamos por la mediana
    df[df[colNameBy] == id & df[colNameData] > highLimit, c(colNameData.R)] <- Me
    
    # lo mismo para el umbral inferior
    df[df[colNameBy] == id & df[colNameData] < lowLimit, c(colNameData.R)] <- Me
    
    cat(paste("El", colNameBy, id, "la mediana(",colNameData,") ==", Me, "\n", sep=" " ))
    
  }
  df   # devolvemos el valor del dataFrame
}
```

## **Evaluación y tratamiento de atípicos**

Se define una función para la identificación e imputación de los valores atípicos basado en el rango intercuartil. Se realiza la imputación con la mediana.

```{r, include= FALSE}
#Heridos
heridos <- datosH
heridos_imputed <- outliersReplace(heridos,"HERIDOS","MES")
heridos_imputed$MES <- as.factor(heridos_imputed$MES)
```

```{r, echo=FALSE}
par(mfrow = c(2,1))    # para ponerlos uno encima de otro

boxplot(HERIDOS   ~ MES, data = heridos_imputed, main = "Sin reemplazo de atípicos", 
        xlab = "Mes", ylab = "Accidentes: Heridos")

boxplot(HERIDOS.R ~ MES, data = heridos_imputed, main = "Con reemplazo de atípicos", 
        xlab = "Mes", ylab = "Accidentes: Heridos")

heridos_imputed <- dplyr :: select(heridos_imputed, -HERIDOS)
```


```{r, include=FALSE}
write.csv(heridos_imputed, file="mensual_h_train.csv", row.names = FALSE)
```

# **Partición de los datos conjuntos de train y test**

Para la validación se usaran los datos de accidentes viales ocurridos en el año 2018.

Datos de Train: Se cuenta 318 observaciones para el entrenamiento de los modelos

```{r particion, echo= FALSE}
heridos_train <- heridos_imputed[heridos_imputed$PERIODO < 2018, ]
heridos_test <- heridos_imputed[heridos_imputed$PERIODO >= 2018, ]

dim(heridos_train)
```

Datos de Test: Se cuenta con 80 observaciones para la validación de los modelos

```{r}
dim(heridos_test)
```

Una vez realizada la partición de los datos, se procede con la eliminación de la variable PERIODO en ambos datasets.

```{r}
heridos_train <- dplyr :: select(heridos_train, -PERIODO)
heridos_test <- dplyr :: select(heridos_test, -PERIODO)
```

# **Modelo de predicción considerados** {.tabset .tabset-fade .tabset-pills}

## **Regresión Lineal**

**Entrenamiento del modelo**

```{r}
heridos_train$SEMANA <- as.factor(heridos_train$SEMANA)

regresion_1 <- lm(HERIDOS.R ~., data = heridos_train)

summary(regresion_1)

```

Las variables MES y SEMANA se incluyeron en el modelo de regresión lineal como factores, vemos ademas, que algunas de las variables incluidad no son significativas para el modelo, pero según el summary se obtuvo un buen R-squared, que explica el 93.28 % de la accidentalidad mensual con gravedad de heridos. De igual manera el valor P del estadístico F es significativo.

**Métricas de Bondad para regresión lineal**

```{r, echo = FALSE}
# Compute R^2 from true and predicted values

heridos_test$SEMANA <- as.factor(heridos_test$SEMANA)
y_pred_train_h <- predict(regresion_1, heridos_train)
y_pred_test_h <- predict(regresion_1, heridos_test)

library(caret)
reg_1 <- data.frame(RMSE_Train = RMSE(y_pred_train_h, heridos_train$HERIDOS.R),
                    Rsquared_Train = R2(y_pred_train_h, heridos_train$HERIDOS.R),
                    RMSE_Test = RMSE(y_pred_test_h, heridos_test$HERIDOS.R),
                    Rsquared_Test = R2(y_pred_test_h, heridos_test$HERIDOS.R))
reg_1
```

Comparando las métricas consideradas tanto para el entrenamiento como para la validación del modelo, observamos que en ambos se obtiene un -squared bueno, superior al 90%. Adicionalmente la variación entre los RMSE es del 36.20%, esta variación es alta, lo que puede indicar sobre entrenamiento.

**Ajuste de las predicciones vs valores reales**

```{r}
plot(y_pred_test_h, heridos_test$HERIDOS.R ,las=1, xlab="Predicciones", ylab = "Accidentes con heridos")
abline(a=1,b=1,lwd=2,col="red")
```

En el gráfico de dispersión se puede observar que el modelo presenta mejor capacidad de predicción para valores bajos que para valores altos de accidentalidad mensual.

## **Árbol Regresor**

**Entrenamiento del modelo**

Se toma el modelo mas simple para el árbol regresor, a partir de este se realizará una búsqueda tipo **grid search** de los parámetros de restricción óptimos. Se definen ademas funciones para extraer el mínimo error asociado con el valor óptimo de costo de complejidad (CP) de cada modelo y  el valor óptimo CP.

```{r}
set.seed(123)
dt_h <- rpart(
  formula = HERIDOS.R ~ .,
  data    = heridos_train,
  method  = "anova"
  )

```

**Representación gráfica del árbol regresor sin tuning**

```{r}
rpart.plot(dt_h)
```

**Ajuste de parámetro de restricción para el árbol regresor**

Se realiza una búsqueda de los parámetros óptimos de minsplit y maxdepth para el árbol regresor: 

En la siguiente gráfica se puede observar el numero optimo de nodos identificado por el modelo que reduce el error asociado. Este sera el punto de partida para definir entre que valores puede variar el parámetro de profundidad del árbol. Vemos que el árbol inicial tiene 5 divisiones y 6 nodos finales.

```{r}

plotcp(dt_h)

dt_sd2 <- rpart(
    formula = HERIDOS.R ~ .,
    data    = heridos_train,
    method  = "anova", 
    control = list(cp = 0, xval = 10)
)

```

El error de validación cruzada asociado es de 0.11, este valor se puede mejorar en el proceso de tuning

```{r, echo= FALSE}
dt_h$cptable
```

El siguiente código define una función grid para la búsqueda de diferentes combinaciones de minsplit y maxdepth. También las funciones que extraen el optimo cp y el mínimo error asociado.

```{r}

hyper_grid_h <- expand.grid(
  minsplit = seq(5, 30, 1),
  maxdepth = seq(5, 8, 1))

models_h <- list()

for (i in 1:nrow(hyper_grid_h)) {
  
  # get minsplit, maxdepth values at row i
  minsplit <- hyper_grid_h$minsplit[i]
  maxdepth <- hyper_grid_h$maxdepth[i]

  # train a model and store in the list
  models_h[[i]] <- rpart(
    formula = HERIDOS.R ~ .,
    data    = heridos_train,
    method  = "anova",
    control = list(minsplit = minsplit, maxdepth = maxdepth)
    )
}

# function to get optimal cp
get_cp <- function(x) {
  min    <- which.min(x$cptable[, "xerror"])
  cp <- x$cptable[min, "CP"] 
}

# function to get minimum error
get_min_error <- function(x) {
  min    <- which.min(x$cptable[, "xerror"])
  xerror <- x$cptable[min, "xerror"] 
}
```

Agregaremos los resultados de la búsqueda a la grilla de hyper-parámetros y filtraremos los 5 valores con error mínimo.

```{r}
hyper_grid_h %>%
  mutate(
    cp    = purrr::map_dbl(models_h, get_cp),
    error = purrr::map_dbl(models_h, get_min_error)
    ) %>%
  arrange(error) %>%
  top_n(-5, wt = error)
```

Vemos que el error se redujo a 0.0865, lo cual indica mejores modelos en comparación con el modelo inicial. Se entrena el árbol regresor con las combinaciones que encabezan los resultados anteriores:

```{r}
optimal_tree_h <- rpart(
    formula = HERIDOS.R ~ .,
    data    = heridos_train,
    method  = "anova",
    control = list(minsplit = 24, maxdepth = 7, cp = 0.01)
    )
```

**Métricas de Bondad para el mejor árbol regresor**

```{r}

heridos_test$MES <- as.factor(heridos_test$MES)
heridos_test$SEMANA <- as.factor(heridos_test$SEMANA)


pred_dt_train = predict(optimal_tree_h, newdata=heridos_train)
pred_dt_test = predict(optimal_tree_h, newdata=heridos_test)


dt_h_op1 <- data.frame(RMSE_Train = RMSE(pred_dt_train, heridos_train$HERIDOS.R),
                    Rsquared_Train = R2(pred_dt_train, heridos_train$HERIDOS.R),
                    RMSE_Test = RMSE(pred_dt_test, heridos_test$HERIDOS.R),
                    Rsquared_Test = R2(pred_dt_test, heridos_test$HERIDOS.R))


dt_h_op1
```

Comparando las métricas consideradas tanto para el entrenamiento como para la validación del árbol optimo, observamos que en ambas se obtuvo buenos R-squared, superiores al 90% aunque un poco mas bajos que los obtenidos en el modelo de regresión lineal. La variación entre los RMSE es del 26.9 %, esta variación es mas baja en comparación con el modelo de regresión lineal, pero aún presenta sobre ajuste.

**Mejor árbol regresor obtenido**

```{r}
library(rpart.plot)
prp(optimal_tree_h)
```

## **Random Forest**

**Entrenamiento del modelo**

Se toma el modelo mas simple, a partir de este se realizará una búsqueda tipo grid search de los hiper parámetros óptimos, mediante el uso de la librería Range. Se analizaron en total 96 modelos diferentes con variaciones en mtry, mínimo tamaño de muestras en el nodo, y tamaño de la muestra.

```{r}
set.seed(101)
rf_h = randomForest(HERIDOS.R ~ ., data = heridos_train)
rf_h
```
Inicialmente, observamos que la varianza explicada por el modelo es del 84,03 %.

**Este gráfico muestra el error vs. el número de árboles**

```{r, echo= FALSE}
plot(rf_h)
```

 **Afinamiento del modelo Random Forest**

Se define la siguiente grilla de búsqueda:

```{r}
set.seed(101)
# hyperparameter grid search
hyper_grid_rf <- expand.grid(
  mtry       = seq(1, 3, by = 1),
  node_size  = seq(7, 21, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

# total number of combinations
#(hyper_grid_rf)
```

Se utiliza la librería Ranger para la búsqueda de los mejores hyper parámetros:

```{r}
for(i in 1:nrow(hyper_grid_rf)) {
  
  # train model
  model <- ranger(
    formula         = HERIDOS.R ~ ., 
    data            = heridos_train, 
    num.trees       = 500,
    mtry            = hyper_grid_rf$mtry[i],
    min.node.size   = hyper_grid_rf$node_size[i],
    sample.fraction = hyper_grid_rf$sampe_size[i],
    seed            = 101
  )
  
  # add OOB error to grid
  hyper_grid_rf$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

hyper_grid_rf %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)
```

Se ajusta el modelo con los mejores hyper parámetros obtenidos:

```{r}
set.seed(101)
mejorRandomforest <- randomForest(HERIDOS.R ~., data = heridos_train, mtry = 3 , 
                                  nodesize = 11, ntree = 500, importance = TRUE)
mejorRandomforest

```

Con la función importance() se extrae la importancia de las variables.

```{r}
library(tidyverse)
library(ggpubr)
importancia_pred <- as.data.frame(importance(mejorRandomforest, scale = TRUE))
importancia_pred <- rownames_to_column(importancia_pred, var = "variable")
p1 <- ggplot(data = importancia_pred, aes(x = reorder(variable, `%IncMSE`),
                                          y = `%IncMSE`,
                                          fill = `%IncMSE`)) +
    labs(x = "variable", title = "Reducción de MSE") +
    geom_col() +
    coord_flip() +
    theme_bw() +
    theme(legend.position = "bottom")

p2 <- ggplot(data = importancia_pred, aes(x = reorder(variable, IncNodePurity),
                                          y = IncNodePurity,
                                          fill = IncNodePurity)) +
    labs(x = "variable", title = "Reducción de pureza") +
    geom_col() +
    coord_flip() +
    theme_bw() +
    theme(legend.position = "bottom")
ggarrange(p1, p2)
```

**Métricas de bondad para modelo de Random Forest**

```{r}
pred_randomForest_t <- predict(mejorRandomforest, heridos_train)
pred_randomForest <- predict(mejorRandomforest, heridos_test)

dt_rf_1 <- data.frame(RMSE_Train = RMSE(pred_randomForest_t, heridos_train$HERIDOS.R),
                    Rsquared_Train = R2(pred_randomForest_t, heridos_train$HERIDOS.R),
                    RMSE_Test = RMSE(pred_randomForest, heridos_test$HERIDOS.R),
                    Rsquared_Test = R2(pred_randomForest, heridos_test$HERIDOS.R))


dt_rf_1
```

Observamos que los R-squared para entrenamiento y validación son mas altos en comparación con los modelos de regresión lineal y Árbol regresor y su variación es mínima. El RMSE presenta una variación del 36%, a pesar de que puede indicar sobre ajuste, por las métricas obtenidas en el R-squared, se define como mejor modelo.


