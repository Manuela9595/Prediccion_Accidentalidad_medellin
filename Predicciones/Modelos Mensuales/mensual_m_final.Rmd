---
title: "**Evaluación de modelos para la predicción mensual de accidentes viales con Gravedad: Muertos**<br>"

author: "*Alexis A. Arenas Bustamante, Juan E. Arroyave Duque, William A. Jovel Tamayo, Manuela Londoño Ocampo.* <br> Curso de Analítica Predictiva <br> Universidad Nacional de Colombia <br> Facultad de Minas <br> Medellín"
date: "Septiembre de 2019"

output:
  html_document:
    theme: cosmo
    highlight: haddock
    number_sections: true
    df_print: paged
    toc: true
    toc_float:
      collapsed: True
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Librerías Necesarias**

```{r, warning=FALSE, message=FALSE}
library(dplyr) # data wrangling
library(ranger)
library(caret)
library(corrplot)
library(rsample)     # data splitting 
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
require(MASS)
library(randomForest)
library(tidyverse)
library(ggpubr)
```

Se consideran tres modelos para la predicción mensual de los accidentes viales con muertos: Regresión lineal, Árbol de regresión y Random Forest. A continuación se presenta la evaluación de cada uno:


# **Dataset propuesto para el modelo mensual de accidentalidad vial : Muertos**

```{r datos_mensuales}
datos_mensualesM <- read.csv("~/Docs/MAESTRIA/ANALITICA PREDICTIVA/Trabajo Final/Datasets/RAPIDM/mensual_m_2.csv", sep=",")

head(datos_mensualesM)
```

# **Estadísticas Descriptivas**  {.tabset .tabset-fade .tabset-pills}

## **Summary del conjunto de datos**

```{r echo = FALSE}
summary(datos_mensualesM)
```

## **Histograma de la variable dependiente**

```{r hitogramas, echo=FALSE}

ggplot(datos_mensualesM, aes(MUERTES)) + 
  geom_histogram(bins=9, fill = "#9999CC", position = 'identity') + 
  xlab("Accidentes con Muertos") + ylab("Frecuencia") +
  theme_classic2()

```

## **Boxplots por mes**

```{r, echo=FALSE}
datosM <- datos_mensualesM 
datosM$MES <- as.factor(datosM$MES)

ggplot(datosM, aes(x=MES, y=MUERTES, fill=MES)) + 
  geom_boxplot(alpha=0.3) +
  xlab("Mes") + ylab("Accidentes con Muertos") +
  theme(legend.position="none") + theme_classic()
```

Se puede observar la presencia de ciertos valores atípicos por mes. Estos se trataran por medio de la imputación con mediana.

## **Correlación entre variables consideradas**

```{r correlacion, echo=FALSE}
library(corrplot)
datosM$MES <- as.integer(datosM$MES)
M <- cor(datosM)
corrplot(M, method = "color")
```

Se puede observar que la variable mas correlacionada con la cantidad de accidentes mensuales con muertos es FESTIVOS. En cada uno de los modelos propuestos se identificará la importancia de las variables, de modo que solo se incluyan aquellas que tengan una influencia significativa sobre la variables dependiente. El periodo no hará parte de ningún modelo puesto que solo se usa para la partición de los datos en conjuntos de entrenamiento y validación.


```{r, include = FALSE}
# df es el dataFrame que recibimos (ej. activity)
# colNameData es la columna de los datos (ej. "steps")
# colNameBy es la columna por la que trocearemos (ej. "userId")

outliersReplace <- function(df, colNameData, colNameBy){
  # creamos una nueva columna llamada igual que colNameData pero con .R
  colNameData.R <- paste(colNameData, "R", sep=".")
  df[colNameData.R] <- df[colNameData]
  
  # obtenemos los IDs por los que partir el dataframe
  IDs <- unique(df[,c(colNameBy)])
  for (id in IDs){
    data <- df[df[colNameBy] == id, c(colNameData) ]
    
    Q  <- quantile(data)
    minimo <- Q[1]    # valor minimo
    Q1     <- Q[2]    # primer cuartil
    Me     <- Q[3]    # mediana
    Q3     <- Q[4]    # tercer cuartil
    maximo <- Q[5]    # valor maximo
    IQR    <- Q3 - Q1
    
    lowLimit  <- max(minimo, Q1 - 1.5*IQR)
    highLimit <- min(maximo, Q3 + 1.5*IQR)
    
    # todos los valores donde colNameBy es igual a id
    # y el valor de colNameData es > Q3 + 1.5 * IQR
    # lo reemplazamos por la mediana
    df[df[colNameBy] == id & df[colNameData] > highLimit, c(colNameData.R)] <- Me
    
    # lo mismo para el umbral inferior
    df[df[colNameBy] == id & df[colNameData] < lowLimit, c(colNameData.R)] <- Me
    
    cat(paste("El", colNameBy, id, "la mediana(",colNameData,") ==", Me, "\n", sep=" " ))
    
  }
  df   # devolvemos el valor del dataFrame
}
```

## **Evaluación y tratamiento de atípicos**

Se define una función para la identificación e imputación de los valores atípicos basado en el rango intercuartil. Se realiza la imputación con la mediana.

```{r, include= FALSE}
#Muertos
muertes <- datosM
muertes_imputed <- outliersReplace(muertes,"MUERTES","MES")
muertes_imputed$MES <- as.factor(muertes_imputed$MES)
```

```{r, echo= FALSE}
par(mfrow = c(2,1))    # para ponerlos uno encima de otro

boxplot(MUERTES   ~ MES, data = muertes_imputed, main = "Sin reemplazo de atípicos",
        xlab = "Mes", ylab = "Accidentes: Muertos")
boxplot(MUERTES.R ~ MES, data = muertes_imputed, main = "Con reemplazo de atípicos",
        xlab = "Mes", ylab = "Accidentes: Muertos")

muertes_imputed <- dplyr ::select(muertes_imputed, -MUERTES)
```

```{r, include = FALSE}
write.csv(muertes_imputed, file="mensual_m_train.csv", row.names = FALSE)
```

# **Partición de los datos conjuntos de train y test**

Para la validación se usaran los datos de accidentes viales ocurridos en el año 2018.

Datos de Train: Se cuenta 318 observaciones para el entrenamiento de los modelos

```{r echo= FALSE}
muertes_train <- muertes_imputed[muertes_imputed$PERIODO < 2018, ]
muertes_test <- muertes_imputed[muertes_imputed$PERIODO >= 2018, ]

dim(muertes_train)
```

Datos de Test: Se cuenta con 80 observaciones para la validación de los modelos

```{r}
dim(muertes_test)
```

Una vez realizada la partición de los datos, se procede con la eliminación de la variable PERIODO en ambos datasets.

```{r}
muertes_train <- dplyr :: select(muertes_train, -PERIODO)
muertes_test <- dplyr :: select(muertes_test, -PERIODO)
```

# **Modelo de predicción considerados** {.tabset .tabset-fade .tabset-pills}

## **Regresión Lineal**

**Entrenamiento del modelo**

```{r}
muertes_train$SEMANA <- as.factor(muertes_train$SEMANA)

regresion_1 <- lm(MUERTES.R ~., data = muertes_train)

summary(regresion_1)

```

Las variables MES y SEMANA se incluyeron en el modelo de regresión lineal como factores, vemos que la mayoría de las varibles no son significativas para el modelo, obteniendo un R-squared de 60.96 %, aunque no es un porcentaje bueno se puede observar que el valor P de estadístico F si es significativo, así que al menos una variable logra explicar la accidentalidad mensual con presencia de muertos.

**Métricas de Bondad para regresión lineal**

```{r, echo = FALSE}

# Compute R^2 from true and predicted values
muertes_test$SEMANA <- as.factor(muertes_test$SEMANA)

y_pred_train_m <- predict(regresion_1, muertes_train)
y_pred_test_m <- predict(regresion_1, muertes_test)

reg_1 <- data.frame(RMSE_Train = RMSE(y_pred_train_m, muertes_train$MUERTES.R),
                    Rsquared_Train = R2(y_pred_train_m, muertes_train$MUERTES.R),
                    RMSE_Test = RMSE(y_pred_test_m, muertes_test$MUERTES.R),
                    Rsquared_Test = R2(y_pred_test_m, muertes_test$MUERTES.R))
reg_1

```

Comparando las métricas consideradas tanto para el entrenamiento como para la validación del modelo, observamos una gran diferencia entre ambos R-squared que en terminos porcentuales es aproximadamente del 66 %. De manera similar, la variación entre los RMSE es del 59.8 %. Lo anterior nos indica que el modelo presenta problemas de sobre entrenamiento. Esto puede deberse a la limitada cantidad de observaciones que se tienen de accidentes cuya gravedad es de muertos.

**Ajuste de las predicciones vs valores reales**

```{r}
plot(y_pred_test_m,muertes_test$MUERTES.R,las=1, xlab="Predicciones", ylab = "Accidentes con Muertos")
abline(a=1,b=1,lwd=2,col="red")

```

En el gráfico de dispersión se puede observar que el modelo de regresión lineal no logra ajustarse de manera óptima a los datos disponible de accidentalidad mensual con presencia de muertos.

## **Árbol Regresor**

**Entrenamiento del modelo**

Se toma el modelo mas simple para el árbol regresor, a partir de este se realizará una búsqueda tipo **grid search** de los parámetros de restricción óptimos. Se definen ademas funciones para extraer el mínimo error asociado con el valor óptimo de costo de complejidad (CP) de cada modelo y el valor óptimo CP.

```{r}
set.seed(123)
dt_m <- rpart(
  formula = MUERTES.R ~ .,
  data    = muertes_train,
  method  = "anova"
  )

```

**Representación gráfica del árbol regresor sin tuning**

```{r, echo = FALSE}
rpart.plot(dt_m)
```

**Ajuste de parámetro de restricción para el árbol regresor**

Se realiza una búsqueda de los parámetros óptimos de minsplit y maxdepth para el árbol regresor: 

En la siguiente gráfica se puede observar el numero óptimo de nodos identificado por el modelo que reduce el error asociado. Este será el punto de partida para definir entre que valores puede variar el parámetro de profundidad del árbol. Vemos que el árbol inicial tiene 6 divisiones y 7 nodos finales.

```{r}
plotcp(dt_m)

dt_sd2 <- rpart(
    formula = MUERTES.R ~ .,
    data    = muertes_train,
    method  = "anova", 
    control = list(cp = 0, xval = 10)
)

```

El error de validación cruzada asociado es de 0.737, este valor se puede mejorar en el proceso de tuning

```{r, echo = FALSE}
dt_m$cptable
```

El siguiente código define una función grid para la búsqueda de diferentes combinaciones de minsplit y maxdepth. También las funciones que extraen el optimo cp y el mínimo error asociado.

```{r}

hyper_grid_m <- expand.grid(
  minsplit = seq(5, 30, 1),
  maxdepth = seq(3, 21, 1)
)

models_m <- list()

for (i in 1:nrow(hyper_grid_m)) {
  
  # get minsplit, maxdepth values at row i
  minsplit <- hyper_grid_m$minsplit[i]
  maxdepth <- hyper_grid_m$maxdepth[i]

  # train a model and store in the list
  models_m[[i]] <- rpart(
    formula = MUERTES.R ~ .,
    data    = muertes_train,
    method  = "anova",
    control = list(minsplit = minsplit, maxdepth = maxdepth)
    )
}

# function to get optimal cp
get_cp <- function(x) {
  min    <- which.min(x$cptable[, "xerror"])
  cp <- x$cptable[min, "CP"] 
}

# function to get minimum error
get_min_error <- function(x) {
  min    <- which.min(x$cptable[, "xerror"])
  xerror <- x$cptable[min, "xerror"] 
}
```

Agregaremos los resultados de la búsqueda a la grilla de hyper-parámetros y filtraremos los 5 valores con error mínimo.

```{r}
hyper_grid_m %>%
  mutate(
    cp    = purrr::map_dbl(models_m, get_cp),
    error = purrr::map_dbl(models_m, get_min_error)
    ) %>%
  arrange(error) %>%
  top_n(-5, wt = error)
```

Vemos que el error se redujo a 0.642, lo cual indica mejores modelos en comparación con el modelo inicial. Se entrena el árbol regresor con las combinaciones que encabezan los resultados anteriores:

```{r}
optimal_tree_m <- rpart(
    formula = MUERTES.R ~ .,
    data    = muertes_train,
    method  = "anova",
    control = list(minsplit = 26, maxdepth = 20, cp = 0.02)
    )
```

**Métricas de Bondad para el mejor árbol regresor**

```{r}

pred_dt_train = predict(optimal_tree_m, newdata=muertes_train)
pred_dt_test = predict(optimal_tree_m, newdata=muertes_test)


dt_h_op1 <- data.frame(RMSE_Train = RMSE(pred_dt_train, muertes_train$MUERTES.R),
                    Rsquared_Train = R2(pred_dt_train, muertes_train$MUERTES.R),
                    RMSE_Test = RMSE(pred_dt_test, muertes_test$MUERTES.R),
                    Rsquared_Test = R2(pred_dt_test, muertes_test$MUERTES.R))


dt_h_op1
```

Comparando las métricas consideradas tanto para el entrenamiento como para la validación del árbol óptimo, observamos que el R-squared de validación es muy bajo en comparación con el de entrenamiento, caso que también se refleja en la variación de los RMSE, que para este caso es del 54,6 %.

**Mejor árbol regresor obtenido**

```{r}
library(rpart.plot)
prp(optimal_tree_m)
```

## **Random Forest**

**Entrenamiento del modelo**

Se toma el modelo mas simple, a partir de este se realizará una búsqueda tipo grid search de los hiper parámetros óptimos, mediante el uso de la librería Range. Se analizaron en total 144 modelos diferentes con variaciones en mtry, mínimo tamaño de muestras en el nodo, y tamaño de la muestra.

```{r}
set.seed(101)
rf_m = randomForest(MUERTES.R ~ ., data = muertes_train)
rf_m
```

Inicialmente, observamos que la varianza explicada por el modelo es del 38,19 %.

**Este gráfico muestra el error vs. el número de árboles**

```{r, echo= FALSE}
plot(rf_m)
```

**Afinamiento del modelo Random Forest**

Se define la siguiente grilla de búsqueda:

```{r}
set.seed(101)
# hyperparameter grid search
hyper_grid_rf <- expand.grid(
  mtry       = seq(1, 3, by = 1),
  node_size  = seq(7, 30, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

# total number of combinations
#nrow(hyper_grid_rf)
```

Se utiliza la librería Ranger para la búsqueda de los mejores hyper parámetros:

```{r}
for(i in 1:nrow(hyper_grid_rf)) {
  
  # train model
  model <- ranger(
    formula         = MUERTES.R ~ ., 
    data            = muertes_train, 
    num.trees       = 500,
    mtry            = hyper_grid_rf$mtry[i],
    min.node.size   = hyper_grid_rf$node_size[i],
    sample.fraction = hyper_grid_rf$sampe_size[i],
    seed            = 101
  )
  
  # add OOB error to grid
  hyper_grid_rf$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

hyper_grid_rf %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)
```

Se ajusta el modelo con los mejores hyper parámetros obtenidos:

```{r}
set.seed(101)
mejorRandomforest <- randomForest(MUERTES.R ~., data = muertes_train, mtry = 3, nodesize = 11, 
                                  ntree = 500, sample_size= 0.8, importance = TRUE)
mejorRandomforest

```

Con la función importance() se extrae la importancia de las variables.

```{r}
library(tidyverse)
library(ggpubr)
importancia_pred <- as.data.frame(importance(mejorRandomforest, scale = TRUE))
importancia_pred <- rownames_to_column(importancia_pred, var = "variable")
p1 <- ggplot(data = importancia_pred, aes(x = reorder(variable, `%IncMSE`),
                                          y = `%IncMSE`,
                                          fill = `%IncMSE`)) +
    labs(x = "variable", title = "Reducción de MSE") +
    geom_col() +
    coord_flip() +
    theme_bw() +
    theme(legend.position = "bottom")

p2 <- ggplot(data = importancia_pred, aes(x = reorder(variable, IncNodePurity),
                                          y = IncNodePurity,
                                          fill = IncNodePurity)) +
    labs(x = "variable", title = "Reducción de pureza") +
    geom_col() +
    coord_flip() +
    theme_bw() +
    theme(legend.position = "bottom")
ggarrange(p1, p2)
```

**Métricas de bondad para modelo de Random Forest**

```{r}
muertes_test$MES <- as.factor(muertes_test$MES)
muertes_test$SEMANA <- as.factor(muertes_test$SEMANA)

pred_randomForest_t <- predict(mejorRandomforest, muertes_train)
pred_randomForest <- predict(mejorRandomforest, muertes_test)

dt_rf_1 <- data.frame(RMSE_Train = RMSE(pred_randomForest_t, muertes_train$MUERTES.R),
                    Rsquared_Train = R2(pred_randomForest_t, muertes_train$MUERTES.R),
                    RMSE_Test = RMSE(pred_randomForest, muertes_test$MUERTES.R),
                    Rsquared_Test = R2(pred_randomForest, muertes_test$MUERTES.R))


dt_rf_1

```

Observamos que el R-squared para entrenamiento es mas altos en comparación con los modelos de regresión lineal y Árbol regresor, además la variación con el R-squared de validación no difiere mucho de la obtenida con el modelo de regresión lineal. A pesar de que el porcentaje de variacion entre RMSE es un poco mayor al obtenido con el árbol regresor, se decide usar este como el mejor para la predicción de accidentes mensuales con gravedad de muertos.



